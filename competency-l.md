---
title: Competency L
---

Competency L
------------

#Each graduate of the Master of Library and Information Science program is able to demonstrate understanding of quantitative and qualitative research methods and of the evaluation and synthesis of research literature.#

##Meaning and Articulation of Competency##

Library and Information Science is just that: a _science_, and research must always be conducted using proper research methods to form questions about information work, to develop hypotheses that try to answer those questions, and to test those hypotheses with experiments.
Information science is a social science, less clear cut then a hard science like physics, and subject to many challenges and pitfalls as a result.
Information professionals cannot rely on guesswork or shoddy research methods to answer questions about their organizations, or they risk having any results discarded completely, wasting everyone's time and money.
An information professional must also be able to follow upon the research that has come before, and integrate it into new work.
Therefor, an information professional must be capable of finding past research, judging the value and validity of that research, combining the results of multiple sources together to discover a more complete whole, and finally to create new research that builds upon this foundation.

##Preparation and Evidence##

I came into the MLIS program familiar with the scientific method and its importance in ensuring validity and consistency of research, but I was not familiar with how it is used in social sciences.
I have since learned that most Information Science research can be characterized as _quantitative_, using concrete numbers and codifiable results, and attempting to be valid by way of large and random sample sizes, and _qualitative_, which uses smaller samples and more open ended questions to find more detailed information [@Smith_quantitative83].
This core dichotomy forms the basis of most social science research techniques.
I have also seen that there are very important ethical concerns in social sciences, since we are researching the lives of real people, and it is vital to always maintain the anonymity and confidentiality of anyone who participates as a research subject.

I have chosen three pieces of evidence from my academic work to show my mastery of this competency.
First is a literature review, tracing and combining what I was able to learn about programs and services for people with developmental disabilities.
The second is a research proposal, designed using quantitative methods to answer questions about the lives of people who are members of online fandom communities.
The third is a critique and analysis of an article that used qualitative methods in its research into the usage and usability of the Internet Public Library.

###First Piece of Evidence: Literature Review, LIBR 200###

In my academic career I have had a great deal of opportunity and experience in conducting library research and synthesizing the works I find, connecting different papers to related topics in order to discover a larger pattern.
Until recently, though, this was always done in the Humanities, with no need or knowledge of social science research methods.
This changed when I started my MLIS career.
In the very first Introduction to Information Science course, which I attended in the Fall of 2011, I was required to create a literature review for use in a later term paper.
As it is a subject with great personal interest for me, I chose this literature review on the topic of library programming and services for people with developmental disabilities.

There were a variety of different kinds of articles that I ended up including in my review, some of which followed rigorous scientific method, while others were more anecdotal.
All of them, though, painted a very similar picture of the state of library services for people with disabilities.
Three studies, in particular, follow quantitative methods, surveys of libraries and library users about their experiences with services for people with disabilities.
One surveyed public library administrators about training for staff, and programs aimed at children with learning disabilities, and found that there was little or no training or specific programs for this population.
Another survey polled people with developmental disabilities directly, finding that, though many did use the library, they did not know about and special programs for them, and did not feel their other information needs were being met by the public library.
A third survey was targeted specifically at the teachers and school librarians who serve children with developmental disabilities, and again this found that there was inadequate training for librarians and few services for people with disabilities, and that the children with disabilities did not use the school library because of this.

Each of these studies, taken individually, surveys a different population and asks different questions, so the results are not directly combinable.
Taken together, though, they do all show a common theme of a lack of services for people with developmental disabilities, and a feeling from these people that their information needs are not being met.
This theme continues with the other papers reviewed for the assignment.
None of them follow proper qualitative design, but even those with personal observations and individual interviews continue the same pattern.
One author describes his experiences with people with mental retardation, who told him that many librarians and other professionals treat them as if they are "stupid", discouraging them from returning.
Another report describes how they have seen a poor attitude from staff drive away children with special needs, as well as their parents.
These experiences combine to show a consistent picture that the libraries involved had poor services for people with developmental disabilities.

This literature review is intended to show my ability to synthesize research literature, noticing trends and connections that accumulate throughout multiple studies and articles.
As researchers and social scientists, we must be careful about finding patterns that may not be there; after all, correlation does not equal causation.
However, it is often necessary to make these connections from smaller studies and even anecdotal evidence, as larger and more valid research may not exist, especially in such subjective and difficult topics as those that are involved in information science.
LIS research is often concerned with what people believe, with what they think about their experiences, with how they feel about the service they have received---or have not received---and as a consequence research must often go forward without hard numbers or rigorous data.
I will of course always strive not let any personal or unconscious bias affect my judgement, but I will also try to see the whole picture based on the different, and often not clearly related, evidence that does exist.

###Second Piece of Evidence: Research Proposal, LIBR 285###

My second piece of evidence for this competency comes from a class on Research Methods that I took during the Spring of 2012.
One of the major final assignments was to create a research proposal for a study involving some aspect of society, using either quantitative or qualitative methods, and including a literature review, a hypothesis about the subject, a question to be answered, a description of the specific methods to be used, and an estimate of the time and money required for the study.
I am fascinated by the devoted fan cultures I have seen, and in some cases participated in, surrounding pop culture franchises such as _Star Trek_ or _My Little Pony: Friendship is Magic_.
I decided to create my proposal to learn about this phenomenon, using quantitative methods to discover if there is any correlation between "fandom" and personality traits, with the underlying hypothesis that fan culture fulfills the same need as more traditional social groups.

When I decided to use quantitative methods, I knew that I would need to develop a specific and measurable question to be answered by the study.
While, ideally, qualitative research also has a specific question to answer, qualitative research is also well suited to exploratory studies used in early research to simply discover more about a topic, with more specific questions developing from the results.
Based on the clarifying description given by @Smith_quantitative83, qualitative research allows for open ended questions and subjects' use of their own words to form answers.
This is in some way inherently subjective, though there are well-established methods for turning these plain-language answers into numbers for statistical analysis.
Quantitative research, on the other hand, usually demands closed questions, with multiple choice or Likert Scale answers used to classify all responses consistently.
Because of this inflexibility, quantitative research is less suitable for open ended studies, and works best with a specific question with answers that can be clearly measured.
For this study, I decided to ask if there is any correlation between participation in an internet-based pop-culture fandom and the Big 5 personality traits.

For the methods of the study, I also followed these guideline when designing the types of questions to be asked.
The questions are divided into several groups, each of which is in support of a _variable_ that can be measured and related to the question.
For example, one set of questions measures the variable _Level of participation in the fandom_ by asking the respondent about whether and how often they have engaged in online discussion of the pop culture franchise, purchased merchandise, or read fanfiction.
Another set of questions measures their participation in other social groups, such as church or local clubs.
A third set measures their personality traits using standard questions for those traits.
All of these are designed so that regression analysis can be used on the results to see if there is any correlation between these variables, and what conclusions can be derived from that.

One potential problem I do see with the survey is the possibility of bias in the selection of people who respond.
As @Couper_web00 describes, web-based surveys are notoriously difficult to get true representative samples from.
Because of impatience, unfamiliarity with the technology, the anonymity of the web, and general frustration, the types of people who will respond to a web-based survey may be quite different than a random sampling of people from the same group conducted in person.
I have tried to make the initial parameters such that this bias is reduced, but it is nearly impossible to eliminate entirely without compromising the nature of the survey, or the privacy of the respondents.

Obviously I have note actually conducted this research---though I would be interested in doing so.
This proposal does show, though, that I understand the fundamentals of quantitative research, including how to create a testable hypothesis and measurable questions to be used in such research.
Quantitative methods are useful any time a specific question needs to be answered about a large number of people, and is the basis of most customer or client satisfaction surveys.
I understand how it works, and how it does not, and I can use such research in my own career going forward so that I can create programs and measure success based on genuine verifiable data, and not just guesswork and opinions.

###Third Piece of Evidence: Research Analysis of an Article, LIBR 285###

The Research Methods course was not, naturally, only concerned with quantitative analysis.
It was concerned with understanding all types of social research, and with being able to analyze and judge the validity of any such research.
For another assignment in the same class, I analyzed a research article that described a qualitative study.
The authors of the study interviewed several university students in order to gauge their knowledge and opinions of the Internet Public Library, in an attempt to judge the IPL's relevance several years after it was first created, and in a world with much higher internet connectivity then when it was first created.

Their questions were exploratory in nature, intended to draw out the students' genuine knowledge and opinions about the IPL, and used open ended questions so that responses would not be limited by too-specific questions that did not have answers that truly reflected their thoughts.
They then coded the responses, looking for common meaning among the words and phrases used, in order to analyze their results.
The results they discovered showed that most of the respondents had not ever heard of the IPL, and while they were enthusiastic about the usefulness of such a resource, they were skeptical about its reliability since they did not know who created or maintained it.
They also expressed a desire for a connection to a live librarian.

I do have a couple concerns with the methods used for this study, as I express in my analysis.
First, the method of coding the verbal responses is unclear in its validity.
Language can be subjective, and as far as is described no attempt was made to clarify particular words or phrases to be certain that they correlate.
Different people may use the same phrase with slightly or very different meaning, and different phrases that may seem synonymous to one person may mean different things to another.
Of greater concern, though, is the potential bias in the respondents chosen.
This study is specifically intended to explore user perceptions and usefulness of the IPL, but the chosen respondents are not the intended audience of the IPL.
The IPL is intended as an online _public_ library, and users of public libraries can have very different needs and perceptions from university students who have had extensive academic library experience.
Any further study should, in my opinion, attempt to select users that are more clearly relevant to the purpose of the IPL.

With this analysis, I have tried to keep in mind the possible future use of the research, by myself or someone else.
The research topic is worthy of study, and though I have questions about the specific methods, they remain sound.
However, even completely valid and rigorous study can be useless if it does not ask the right questions of the right people.
I have shown how this study, though it uses effective qualitative methods to answer its questions, may still fail this test because it does not use the right subjects.
Nonetheless, though the results are limited they are not useless, and can be used as the basis of further research that sets out with the right parameters from the beginning.

##Future Application##

The purpose of research is to discover the facts, to find out how things work and why.
It can also be used to find out how things fail to work and why.
Information science is a difficult field to measure, to codify, and most especially to judge.
As information professionals, we should always be seeking to improve the service that we give, but this is impossible if we cannot judge the effectiveness of the service that we give.
For us, then, the greatest purpose of social research is to enable us to truly answer what is working and what is not, and over time to judge if something is improving or not.
It can also give us great insight into the minds, feelings, and lives of our users, which will help us to understand what they think of our service and how they would _like_ it to be.
Though I do not truly believe in wasted research, just as I do not believe in useless information, the value of both can be much more clearly seen if they can be connected to improved service for our users.

##References##


